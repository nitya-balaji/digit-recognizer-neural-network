{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724309fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required libraries \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88440ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data \n",
    "data = pd.read_csv('train.csv') #in this file, 1 row = 1 image\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6335baf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to a NumPy matrix to complete linear algebra operations\n",
    "data = np.array(data)\n",
    "m, n = data.shape #m = number of images (42,000), n is pixels+1 (785)\n",
    "#shuffling data to prevent the network from \"memorizing\" the order of the data\n",
    "np.random.shuffle(data)\n",
    "\n",
    "#dev batch\n",
    "#taking the first 1000 images and transposing them -> turns \"Rows=Images\" into \"Rows=Pixels\"\n",
    "data_dev = data[0:1000].T\n",
    "Y_dev = data_dev[0] #the \"answer key\" for each of these 1000 images\n",
    "X_dev = data_dev[1:n] #the \"input layer\" (the pixels)\n",
    "X_dev = X_dev/255 #squish 0-255 to 0-1 (activation range)\n",
    "\n",
    "#training batch - do the same for the remaining 41,000 images\n",
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0] #the correct labels\n",
    "X_train = data_train[1:n] #the input pixels\n",
    "X_train = X_train/255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a71342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, 0].shape #confirming that the first column has 784 pixels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeaeb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize params \n",
    "def init_params(): \n",
    "    #W1: weights connecting Input (784) to hidden layer (10)\n",
    "    #this means: every one of the 10 hidden neurons needs a weight for all the 784 pixels - that is 10 x 784 = 7840 connections\n",
    "    #subtracting 0.5 to get weights btwn -0.5 and 0.5 (bc if all the weights are positive (0 to 1), every neuron will likely fire very strongly right at the start)\n",
    "    W1 = np.random.rand(10, 784) - 0.5 \n",
    "    b1 = np.random.rand(10, 1) - 0.5 #each of the 10 neurons have their own bias\n",
    "    W2 = np.random.rand(10, 10) - 0.5 #weights connecting hidden layer (10) to output (10)\n",
    "    b2 = np.random.rand(10,1) - 0.5\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "#define ReLU\n",
    "def ReLU(Z):\n",
    "    return np.maximum(0,Z)  #represents same idea as ReLU piecewise function\n",
    "\n",
    "#define Softmax\n",
    "def softmax(Z): # softmax takes raw scores of 10 output neurons and turns them into probabilities that sum to 100%\n",
    "    A = np.exp(Z)\n",
    "    return A / np.sum(A, axis=0) #axis=0 ensures we sum down the columns\n",
    "    \n",
    "\n",
    "#forward propagation\n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1 #calculate weighted sum for first hidden layer \n",
    "    A1 = ReLU(Z1) #get activation of each neuron within first hidden layer using ReLU \n",
    "    Z2 = W2.dot(A1) + b2 #apply the same process to get the weighted sum of output layer (this time we are using activation of each neuron in previous layer - A1)\n",
    "    A2 = softmax(Z2) #apply softmax to get probability for activation of each neuron for output layer \n",
    "    return Z1, A1, Z2, A2\n",
    "    \n",
    "#before completing backprop we need to one hot encode Y\n",
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max()+1)) #create a grid of zeros\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1 #put a \"1\" in the correct digit's spot - e.g. if the image is a 3 we want the 4th neuron to be at max brightness -> [0,0,0,1,0,0,...0]\n",
    "    one_hot_Y = one_hot_Y.T #flipping so that each column is an example (matches our layer orientation)\n",
    "    return one_hot_Y\n",
    "\n",
    "#slope of the activation function.If the neuron fired (Z > 0), the slope is 1. If not, it's 0. We need this for the 'Chain Rule' to know how much to nudge\n",
    "def deriv_ReLU(Z):\n",
    "    return Z > 0 #for booleans - true converts to 1, while false converts to 0\n",
    "\n",
    "#backpropagation\n",
    "def back_prop(Z1, A1, Z2, A2, W2, X, Y):\n",
    "    m = Y.size #gets the number of training examples (batch size)\n",
    "    one_hot_Y = one_hot(Y) #this is our desired output (compare our guess, A2 against this value)\n",
    "    dZ2 = A2 - one_hot_Y #error of output layer (\"nudge to the activation\")\n",
    "    dW2 = 1/m * dZ2.dot(A1.T) #calculates how to change the weights btwn the hidden layer and output (weight's influence depends on the activation of the neuron it comes from - A1)\n",
    "    #axis=1 sums rows; keepdims=True keeps it as (10,1) instead of (10,)\n",
    "    db2 = 1 / m * np.sum(dZ2, axis=1, keepdims=True)  #the average nudge for the biases (don't have \"previous activation\" attached to them - so sum the raw error)\n",
    "    \n",
    "    #note: here, 1/m is the avg part of the mean squared error (bc we are dealing with 41,000 training examples here), while the second half of each of those eqns are just the \"nudge calculation (aka backprop)\"\n",
    "    dZ1 = W2.T.dot(dZ2) * deriv_ReLU(Z1) #this is the idea of the chain rule - we are backpropagating to the hidden layer (We take the output error (dZ2), multiply by the weights (W2.T) to see how much the hidden layer contributed to the mistake, and then multiply by the derivative of the activation function (deriv_ReLU))\n",
    "    dW1 = 1 / m * dZ1.dot(X.T) #nudges for weights btwn the input (pixels) and hidden layer\n",
    "    db1 = 1 / m * np.sum(dZ1, axis=1, keepdims=True) #avg nudge for the hidden layer biases \n",
    "    \n",
    "    return dW1, db1, dW2, db2 #retusn the \"Gradient\" - the direction of the \"steepest descent\" down the cost function/cost hill\n",
    "\n",
    "#update params - alpha is the learning rate AKA step size \n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1 #subtracting to keep going down the cost hill to find the minimum error (applies to all other lines in this function)\n",
    "    W2 = W2 - alpha * dW2\n",
    "    b1 = b1 - alpha * db1\n",
    "    b2 = b2 - alpha * db2\n",
    "    return W1, b1, W2, b2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65bf442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2):\n",
    "    #idea: look at the 10 output neurons. Which one is 'brightest'?\n",
    "    return np.argmax(A2, 0) #finding the index (0-9) of the highest number in the output layer -> [0.1,0.05, 0.8,...] - argmax picks index 2\n",
    "\n",
    "def get_accuracy(predictions, Y): #comparing the brightest neuron to the actual label from the CSV\n",
    "    print(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "def gradient_descent(X,Y, iterations,alpha):\n",
    "    W1, b1, W2, b2 = init_params() #start at a random spot on the cost hill/function\n",
    "    for i in range(iterations): #repeat the learning process\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X) #\"think\" (process the image and make a guess)\n",
    "        dW1, db1, dW2, db2 = back_prop(Z1, A1, Z2, A2, W2, X, Y) #network looks at the \"answer key\" (Y) to see how wrong its \"think\" was and find the nudges\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha) #step down\n",
    "        #to check our progress, for every 10th iteration we will print the iteration we are on and the accuracy \n",
    "        if (i % 10 == 0):\n",
    "            print('Iteration: ', i)\n",
    "            print('Accuracy: ', get_accuracy(get_predictions(A2), Y))\n",
    "    #the training loop is over. We return the final version of the weights and biases, which have been 'nudged' over many iterations to reside \n",
    "    #in a low-cost area of the landscape. These are our 'trained' parameters.\n",
    "    return W1, b1, W2, b2   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72bbd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[8 8 8 ... 0 8 8] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.07097560975609755\n",
      "Iteration:  10\n",
      "[7 8 1 ... 1 4 6] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.24751219512195122\n",
      "Iteration:  20\n",
      "[7 8 1 ... 1 4 6] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.3643658536585366\n",
      "Iteration:  30\n",
      "[3 8 1 ... 1 4 6] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.42990243902439024\n",
      "Iteration:  40\n",
      "[3 8 1 ... 1 4 6] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.4899512195121951\n",
      "Iteration:  50\n",
      "[3 8 1 ... 1 4 6] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.5428780487804878\n",
      "Iteration:  60\n",
      "[8 8 1 ... 1 4 6] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.5908780487804878\n",
      "Iteration:  70\n",
      "[8 8 1 ... 1 4 6] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.6291463414634146\n",
      "Iteration:  80\n",
      "[8 8 1 ... 1 4 8] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.660609756097561\n",
      "Iteration:  90\n",
      "[8 8 1 ... 1 4 8] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.6844634146341464\n",
      "Iteration:  100\n",
      "[8 8 1 ... 1 4 8] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.7053414634146341\n",
      "Iteration:  110\n",
      "[8 8 1 ... 1 4 8] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.7214878048780488\n",
      "Iteration:  120\n",
      "[8 8 1 ... 1 4 8] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.7341219512195122\n",
      "Iteration:  130\n",
      "[8 8 1 ... 1 4 8] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.7462926829268293\n",
      "Iteration:  140\n",
      "[8 8 1 ... 1 4 8] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.7562926829268293\n",
      "Iteration:  150\n",
      "[8 8 1 ... 1 4 8] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.765390243902439\n",
      "Iteration:  160\n",
      "[4 8 1 ... 1 4 8] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.7723414634146342\n",
      "Iteration:  170\n",
      "[4 8 1 ... 1 4 8] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.7796829268292683\n",
      "Iteration:  180\n",
      "[4 8 1 ... 1 4 8] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.7858536585365854\n",
      "Iteration:  190\n",
      "[4 8 1 ... 1 4 8] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.791219512195122\n",
      "Iteration:  200\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.7956829268292683\n",
      "Iteration:  210\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8012439024390244\n",
      "Iteration:  220\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8058536585365854\n",
      "Iteration:  230\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8091951219512196\n",
      "Iteration:  240\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8128292682926829\n",
      "Iteration:  250\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8164634146341463\n",
      "Iteration:  260\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8194878048780487\n",
      "Iteration:  270\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.822390243902439\n",
      "Iteration:  280\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8253658536585365\n",
      "Iteration:  290\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8278292682926829\n",
      "Iteration:  300\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.83\n",
      "Iteration:  310\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8320731707317073\n",
      "Iteration:  320\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8348536585365853\n",
      "Iteration:  330\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8373170731707317\n",
      "Iteration:  340\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8390243902439024\n",
      "Iteration:  350\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8410731707317073\n",
      "Iteration:  360\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8426829268292683\n",
      "Iteration:  370\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8441463414634146\n",
      "Iteration:  380\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8462195121951219\n",
      "Iteration:  390\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.847780487804878\n",
      "Iteration:  400\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8493658536585366\n",
      "Iteration:  410\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8507073170731707\n",
      "Iteration:  420\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8522682926829268\n",
      "Iteration:  430\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8536829268292683\n",
      "Iteration:  440\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8550975609756097\n",
      "Iteration:  450\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.856390243902439\n",
      "Iteration:  460\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8574634146341463\n",
      "Iteration:  470\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8584634146341463\n",
      "Iteration:  480\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8594634146341463\n",
      "Iteration:  490\n",
      "[4 8 1 ... 1 4 5] [5 6 1 ... 1 4 5]\n",
      "Accuracy:  0.8605121951219512\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 500, 0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7dc9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2): #let the network make a prediction by going through forward prop\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions\n",
    "\n",
    "def test_prediction(index, W1, b1, W2, b2):\n",
    "    current_image = X_train[:, index, None]\n",
    "    prediction = make_predictions(X_train[:, index, None], W1, b1, W2, b2)\n",
    "    label = Y_train[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "    \n",
    "    current_image = current_image.reshape((28, 28)) * 255 #turn vector back into a square\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest') #draw it on the screen\n",
    "    plt.show() #display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bbd6eb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [9]\n",
      "Label:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [1]\n",
      "Label:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(8,W1,b1,W2,b2)\n",
    "test_prediction(2,W1,b1,W2,b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "75599f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 6 1 5 5 4 1 1 0 2 3 3 3 2 8 9 8 3 7 7 1 3 9 1 5 4 3 7 6 7 7 6 4 4 6 0 7\n",
      " 1 8 3 0 3 1 7 8 7 2 2 7 0 1 5 1 0 5 8 7 2 9 9 1 2 9 5 5 0 6 0 8 6 5 7 8 0\n",
      " 4 4 1 8 7 0 4 6 6 9 2 9 4 6 1 5 9 7 6 7 8 4 5 9 7 0 3 0 0 6 1 8 8 5 7 9 2\n",
      " 9 4 0 0 7 5 9 6 2 6 2 0 1 3 6 4 6 7 9 7 8 5 7 0 8 3 5 8 2 1 3 2 1 6 5 4 2\n",
      " 0 7 8 4 7 2 2 2 0 4 6 9 5 7 3 7 7 2 4 2 2 1 9 4 9 0 4 1 0 3 2 6 7 2 9 5 5\n",
      " 9 0 5 8 8 8 0 0 0 7 3 5 2 7 2 0 3 2 8 0 2 4 6 6 4 8 6 5 0 7 6 0 8 1 4 3 8\n",
      " 4 6 7 6 0 1 2 1 7 8 8 5 5 0 0 6 8 6 6 1 1 3 1 4 6 7 3 9 9 9 2 6 4 0 6 6 4\n",
      " 1 3 6 9 4 3 8 6 3 5 9 0 9 0 7 7 3 7 8 7 1 8 4 1 4 6 1 1 8 9 3 7 3 4 1 6 7\n",
      " 4 0 8 0 4 3 5 1 3 5 2 7 0 4 6 2 2 1 6 1 0 6 1 8 3 9 5 3 3 3 1 5 1 8 2 9 3\n",
      " 5 6 3 8 9 2 6 4 6 3 2 6 5 8 2 8 6 9 3 9 8 4 3 0 8 5 4 0 1 8 1 2 4 4 6 2 8\n",
      " 1 9 8 0 6 1 1 2 6 9 1 4 4 0 3 6 5 5 3 3 1 0 0 6 3 8 4 5 6 1 7 7 1 0 1 1 6\n",
      " 3 9 5 3 1 4 6 7 0 1 7 6 1 7 3 2 3 8 2 7 2 5 0 9 6 6 1 5 0 2 2 6 2 3 7 2 7\n",
      " 9 7 8 6 6 1 1 4 3 4 9 9 4 2 8 0 8 0 9 5 3 6 2 2 5 5 6 7 3 4 5 7 6 3 8 8 3\n",
      " 6 0 8 6 9 7 0 2 4 0 1 4 5 5 1 7 8 2 8 7 6 4 8 7 4 8 1 5 7 5 7 3 7 7 7 1 9\n",
      " 8 9 0 3 3 7 4 0 6 7 0 7 4 3 9 8 2 6 2 7 0 2 2 0 0 4 0 9 9 6 9 5 4 2 1 8 5\n",
      " 8 7 6 2 7 6 0 7 8 7 0 4 6 4 7 6 3 3 6 6 1 8 4 5 0 9 1 6 6 5 3 4 5 0 8 8 1\n",
      " 6 1 0 9 5 8 3 9 1 1 0 8 2 4 1 1 8 1 3 7 9 2 3 7 9 5 4 8 5 5 9 5 8 8 0 6 0\n",
      " 4 2 4 8 7 7 2 4 4 1 2 4 1 8 0 9 4 7 8 1 0 0 1 6 3 5 8 0 0 3 3 0 1 9 1 8 0\n",
      " 4 3 4 5 0 9 4 7 1 3 3 1 2 9 3 5 2 7 4 3 6 5 2 6 6 8 0 1 9 4 8 1 7 6 1 6 1\n",
      " 3 1 3 7 2 9 2 1 3 6 3 8 3 3 9 1 0 1 1 9 8 1 6 9 8 4 1 2 5 0 9 0 4 6 1 5 2\n",
      " 7 3 1 7 3 7 8 9 8 3 6 6 5 1 2 7 0 9 1 9 3 6 3 2 1 4 5 5 0 4 4 5 3 8 8 2 5\n",
      " 2 8 0 9 2 9 0 4 4 5 8 9 9 4 6 3 2 3 4 2 4 5 9 9 7 1 7 6 9 3 6 5 5 4 1 4 4\n",
      " 2 4 1 8 9 3 8 9 5 8 7 9 3 2 1 0 2 1 3 4 0 0 5 1 7 6 9 9 3 0 3 7 7 7 5 8 9\n",
      " 6 9 7 4 9 4 9 8 6 4 4 0 3 5 6 8 8 2 0 7 0 5 0 1 8 3 6 2 7 2 6 4 1 1 9 7 6\n",
      " 1 8 4 8 8 1 9 6 1 9 9 1 5 5 0 5 1 7 8 2 1 1 7 4 2 1 6 4 4 3 9 6 0 5 7 3 7\n",
      " 1 1 3 8 6 7 8 8 2 4 7 6 1 1 6 8 9 3 4 9 0 6 7 9 0 5 6 4 8 1 3 4 7 2 1 1 6\n",
      " 3 1 6 7 7 3 4 2 1 9 9 4 5 0 4 2 4 5 1 3 6 9 5 0 7 2 3 3 0 7 0 9 8 5 7 1 0\n",
      " 6] [4 6 1 5 5 2 1 1 0 2 3 3 3 3 8 9 5 3 7 7 2 3 4 1 3 4 3 7 6 7 7 6 4 9 6 0 7\n",
      " 1 3 3 0 3 1 7 5 7 2 8 7 7 1 5 1 0 5 8 7 2 9 9 1 2 9 5 5 0 6 0 8 6 3 7 8 0\n",
      " 4 4 5 3 7 0 4 6 6 9 2 9 4 6 1 5 9 7 6 7 8 4 5 9 7 0 3 3 0 2 1 3 8 8 7 9 2\n",
      " 7 4 0 0 7 5 9 6 2 6 2 0 1 3 6 4 6 7 9 7 8 5 7 0 8 5 5 8 2 1 5 2 1 6 8 4 2\n",
      " 0 7 8 4 7 2 2 2 0 4 8 9 5 7 5 7 7 2 4 6 2 1 4 4 9 0 6 1 9 3 2 6 7 2 4 5 3\n",
      " 9 0 5 8 3 5 0 0 0 7 3 5 2 7 2 0 3 2 3 0 6 4 6 6 4 8 2 5 0 7 6 0 8 1 4 3 8\n",
      " 4 6 7 6 3 1 3 1 7 3 8 5 6 0 0 6 8 4 6 1 8 3 1 4 6 7 2 9 9 9 2 4 4 0 6 6 4\n",
      " 1 3 6 9 7 5 3 6 3 5 9 0 9 0 7 7 5 7 8 7 1 8 4 1 4 6 1 1 8 9 3 7 3 9 1 6 7\n",
      " 4 5 8 0 4 3 5 1 3 5 2 7 0 4 1 9 7 1 6 1 0 6 1 8 3 4 5 3 3 3 1 5 1 5 2 9 3\n",
      " 5 6 3 8 9 2 6 4 6 3 2 6 5 8 8 8 6 9 3 9 8 4 3 0 8 5 4 0 1 8 1 5 9 4 6 2 8\n",
      " 1 9 8 0 6 2 1 0 6 9 1 4 4 0 3 2 5 5 3 3 1 0 0 6 3 8 4 8 6 1 7 7 1 0 1 1 6\n",
      " 3 9 8 8 8 4 6 7 0 1 7 5 1 7 3 2 3 8 2 7 2 5 0 9 6 6 1 5 0 4 2 4 2 3 7 2 7\n",
      " 9 5 8 6 6 1 1 4 3 9 4 9 3 2 8 0 6 0 9 8 2 6 2 2 5 5 6 5 3 4 5 7 6 3 1 8 3\n",
      " 6 0 8 6 9 7 0 2 2 0 1 9 8 5 1 7 8 2 3 7 6 9 8 7 7 8 1 0 7 5 7 3 7 7 2 1 9\n",
      " 8 9 0 3 3 7 4 0 6 7 0 7 4 3 5 8 2 8 2 7 0 2 7 0 0 4 0 8 9 2 9 5 4 2 1 8 5\n",
      " 8 7 6 2 7 6 0 7 8 7 0 4 6 4 7 6 3 3 6 6 1 8 4 5 7 9 1 6 5 5 3 9 5 0 8 8 1\n",
      " 6 1 5 7 5 8 3 4 1 1 0 8 2 4 1 1 8 1 3 7 9 2 5 7 9 5 4 8 5 2 9 5 8 5 0 6 0\n",
      " 4 2 4 8 7 7 6 4 4 1 2 4 1 8 0 9 4 7 8 1 0 0 1 6 3 5 8 0 0 3 3 0 1 9 1 8 3\n",
      " 5 3 4 5 0 9 9 7 1 3 3 1 2 9 5 5 2 7 4 3 6 5 2 0 6 8 0 1 9 4 8 1 7 6 1 5 1\n",
      " 3 1 3 7 2 9 2 1 5 6 3 8 3 3 9 1 0 1 1 9 8 1 6 9 8 4 1 2 5 0 4 0 9 6 1 5 2\n",
      " 7 3 8 7 0 7 1 9 5 3 6 6 5 1 2 7 0 9 1 9 3 6 3 2 1 5 8 5 0 4 4 5 3 8 8 2 5\n",
      " 2 1 0 9 2 5 0 4 5 5 8 9 9 4 6 5 2 3 4 2 4 5 9 9 3 1 7 6 9 3 6 5 5 4 1 4 4\n",
      " 2 4 1 8 9 3 8 9 5 8 7 9 5 2 1 0 2 1 3 4 5 0 5 1 7 5 9 8 5 0 3 7 7 7 5 8 5\n",
      " 6 9 7 4 4 4 9 8 5 4 6 0 3 5 0 7 8 2 0 7 0 9 0 1 5 2 6 2 7 6 6 4 1 1 9 7 5\n",
      " 1 8 4 1 8 1 9 6 1 7 9 1 5 5 0 5 1 7 8 2 1 1 7 4 2 1 6 4 4 3 9 6 0 5 7 3 7\n",
      " 1 1 3 2 6 7 2 8 2 4 7 5 1 1 6 8 9 3 4 9 0 6 7 4 0 5 6 4 5 1 3 4 7 2 1 1 0\n",
      " 3 1 5 9 7 3 4 2 1 4 9 4 5 0 4 2 4 5 1 3 6 9 6 0 7 2 3 3 0 7 0 7 8 5 7 1 0\n",
      " 6]\n",
      "Accuracy: 85.20%\n"
     ]
    }
   ],
   "source": [
    "#checking cross-validation accuracy\n",
    "dev_predictions = make_predictions(X_dev, W1, b1, W2, b2)\n",
    "acc = get_accuracy(dev_predictions, Y_dev)\n",
    "print(f\"Accuracy: {acc * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
